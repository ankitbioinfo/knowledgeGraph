{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ab8ad4c-ea13-4049-9f02-3542b6510028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random\n",
    "from gensim.models import Word2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "067d83f6-b0fb-4010-be1f-acbae6d72896",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load and build graph\n",
    "df1 = pd.read_csv('83332.protein_chemical.links.detailed.v5.0.tsv', sep='\\t')\n",
    "df = df1.sort_values(by='experimental', ascending=False).head(10000)\n",
    "\n",
    "G = nx.Graph()\n",
    "for _, row in df.iterrows():\n",
    "    G.add_edge(row['chemical'], row['protein'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e40df0ba-4e2a-4248-be52-75d0f53009a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The walk length parameter controls the length of the sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faaaaf18-9312-4933-b1eb-c6e8e304651f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_walks(graph, num_walks=10, walk_length=40):\n",
    "    walks = []\n",
    "    nodes = list(graph.nodes())\n",
    "    for _ in range(num_walks):\n",
    "        random.shuffle(nodes)\n",
    "        for node in nodes:\n",
    "            walk = [node]\n",
    "            while len(walk) < walk_length:\n",
    "                cur = walk[-1]\n",
    "                neighbors = list(graph.neighbors(cur))\n",
    "                if not neighbors:\n",
    "                    break\n",
    "                walk.append(random.choice(neighbors))\n",
    "            walks.append(walk)\n",
    "    return walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "571e15d5-8acb-4368-8734-5c7d5a89b6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "walks = generate_walks(G, num_walks=10, walk_length=40)\n",
    "walks = [[str(node) for node in walk] for walk in walks]  # gensim requires string tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "934fa73d-da19-4ef4-b7f9-11461aef42c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Step 3: Train skip-gram Word2Vec -----\n",
    "model = Word2Vec(walks, vector_size=128, window=5, min_count=0, sg=1, workers=4, epochs=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09f47386-28a1-4eb9-ba9e-7d8523a52911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get node embeddings\n",
    "node_embeddings = {node: model.wv[str(node)] for node in G.nodes()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5c19efa-d6e3-4e53-8474-3e29c008c86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.52443624 -0.3476105   0.01923808  0.4527632   0.16446231 -0.19755913\n",
      "  0.61542445 -0.27943638 -0.21119517  0.03559417  0.79908127 -0.09800877\n",
      "  0.20827083 -0.1379976  -0.1702288  -0.09208585 -0.02668916 -0.04828003\n",
      "  0.39084968  0.34057876  0.03246465 -0.25889388 -0.43645644  0.04061414\n",
      " -0.3772784   0.40476128 -0.19017018  0.24968255  0.3729445   0.03554049\n",
      "  0.26007432 -0.20732394  0.05482044 -0.03231744  0.10476781 -0.07450484\n",
      "  0.69226366 -0.08950389 -0.46971202  0.2164383   0.7513727  -0.03014943\n",
      "  0.7825339  -0.06433287  0.39059412 -0.1443428  -0.3028992   0.03753158\n",
      " -0.27578613  0.17242607  0.42469478 -0.4380793   0.16107403 -0.11150428\n",
      " -0.2349694   0.17533697  0.22437207 -0.53638905 -0.01945447  0.19055508\n",
      " -0.40911645  0.18357572  0.37003237  0.22836605  1.1182557   0.19173728\n",
      "  0.08634968  0.00980959 -0.13673666 -0.01474925  0.21137881 -0.18959641\n",
      "  0.2613215   0.09936649  0.20712517  0.00899029 -0.15823235 -0.18468815\n",
      " -0.4680551   0.11637086  0.30118334 -0.10733818  0.13860227  0.33655882\n",
      "  0.45612106  0.15068862  0.39703107  0.50225943 -0.810922    0.16765203\n",
      " -0.419957   -0.15200587 -0.5284429  -0.3410881   0.11196791  0.39804968\n",
      "  0.10030881 -0.21403861 -0.12425252  0.11791871 -0.3418377   0.1735093\n",
      " -0.03357001 -0.43957025 -0.2186315  -0.40010065 -0.03525489 -0.17505841\n",
      "  0.48802775  0.38173455  0.46804914 -0.21634544 -0.07865223 -0.5234886\n",
      " -0.47605562 -0.3222965   0.1054094  -0.13952711  0.17647386  0.556252\n",
      "  0.08794063 -0.7807925   0.04583336  0.26449975 -0.24213757 -0.3922559\n",
      " -0.5808678   0.0211353 ]\n"
     ]
    }
   ],
   "source": [
    "# Example: embedding for a chemical/protein\n",
    "print(node_embeddings[list(G.nodes())[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be3e67a7-988a-43e1-b1a0-2db0406f4b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Helper: Create edge embedding\n",
    "def get_edge_embedding(u, v):\n",
    "    return model.wv[u] * model.wv[v]  # Could also try concat or average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dade55b1-7f45-49a9-b2bf-482a87be8e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Positive samples (existing links)\n",
    "positive_edges = list(G.edges())\n",
    "X_pos = [get_edge_embedding(u, v) for u, v in positive_edges]\n",
    "y_pos = [1] * len(X_pos)\n",
    "\n",
    "# Negative samples (non-existent links)\n",
    "nodes = list(G.nodes())\n",
    "negative_edges = []\n",
    "while len(negative_edges) < len(positive_edges):\n",
    "    u, v = random.sample(nodes, 2)\n",
    "    if not G.has_edge(u, v) and u[0] != v[0]:  # Ensure bipartite: avoid same-type nodes\n",
    "        negative_edges.append((u, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e17a2c29-af6c-4357-9622-faa43b9c8c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9500\n"
     ]
    }
   ],
   "source": [
    "X_neg = [get_edge_embedding(u, v) for u, v in negative_edges]\n",
    "y_neg = [0] * len(X_neg)\n",
    "\n",
    "# Combine and classify\n",
    "X = X_pos + X_neg\n",
    "y = y_pos + y_neg\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"AUC: {roc_auc_score(y_test, y_pred):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
